---
title: Kaggle Playground Top 11.68% Review 
date: 2026-01-17
author: Akai Red
image: 
tags: ['kaggle']
published: false
---

여러 가지 생각을 거쳐 새해에는 Kaggle을 꾸준히 해서 그럴싸한 성과를 한 번 해보자는 목표를 세웠다. Kaggle에 가입한지는 오래됐지만, 제대로 하지 않아서 성적도 별로 좋지 않았다.

![기존 최고 성적은 Top 29%다.](/imgs/2026-01-17-kaggle-s6e1-02.png)  

Kaggle Playground라고 매달 Kaggle에서 진행하는 정형 데이터 분석 Competition이 있는데, 금전적 보상이나 메달을 주지 않음에도 Kaggle Grandmaster를 포함해 꽤나 많은 사람들이 꾸준히 도전한다. 

입문 장벽이 낮다보니 나도 이전에 Kaggle을 하고 싶을때면 종종 문을 두드렸는데, **올해는 Top 10%을 목표로 했다.**

![1/16일 기준 나의 Kaggle 최고 성적 상위 11.68%](/imgs/2026-01-17-kaggle-s6e1-01.png)  


## Week 1. Blind Script, Gemini

## Week 2. Boosting over Residual
### Linear Model → Non Linear Model

### Target Encoding

### CV without Data Leakage

### OOF predictions and Stacking

## Week 3. Back to Single Model

## Week 4. The Power of Mathematical Formula

에서 흥미로운 댓글을 보았다.

내 모델은 3단계로 이루어져 있다.

- 1. 선형 모델: 데이터의 큰 틀에서의 경향성을 잡는다.
- 2. 비선형 모델: 선형 모델이 예측하지 못한 부분을 비선형 모델로 세밀하게 잡는다.
- 3. 메타 모델: 여러 가지 비선형 모델의 예측을 기반으로 최종 예측을 낸다.

상당히 낮아진 RMSE를 쥐어짜는 단계에 들어왔는데, 이 단계에서 새롭게 시도해본 선형 모형이 RMSE를 0.01이나 줄이는 효과를 보여줬다.

![picture 0](../../images/1dc7c9973553bff1fe56f6756eac71047524231638a31a91779f7aac7674069e.png)  

![picture 1](../../images/2f46223e57038b95d284086cb5eb98b26296fa8dd79538d5d06cdbe5cbbb114a.png)  

원본 디스커션에 대한 깊은 이해는 부족하다(못하겠다). 이러한 선형 회귀 결과를 feature로 사용한 다른 코드를 참고

![1/19 기준 나의 Kaggle 최고 성적 상위 10.01%](../../images/b8da9ea53568f3a098ad8bf18a816140330b6ae2cea58c3e704b54274d91fd71.png)  


![Kaggle Grandmaster Chris Deotte 근처에 있는 모습](../../images/9792a487fc4bf19e64dec88876dbbb25acd1dd9b0c14f2926bb27983a7ac2a0d.png)  


## References
- [Recovering the "original" data model](https://www.kaggle.com/competitions/playground-series-s6e1/discussion/665915)