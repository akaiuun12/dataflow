---
layout: post
category: Python
tags: ['data preprocessing']

date: 2024-08-29
author: Akai Red
title: Pandas Basic - 데이터프레임 다루기
description: 
    pandas는 2차원 테이블 데이터를 다루는데 최적화된 라이브러리다.

image: 
    # https://res.cloudinary.com/dhchweuhy/image/upload/c_fill,w_760,h_399,r_5,f_auto,q_auto/lrc/20220301_img1
optimized_image: 
    # https://res.cloudinary.com/dhchweuhy/image/upload/c_fill,w_380,h_200,r_5,f_auto,q_auto/lrc/20220301_img1

show_thumbnail: true
math: true
published: true
---

pandas는 2차원 테이블 형태로 된 데이터를 다루는데 최적화된 Python 라이브러리다. Numpy와는 컬럼명 지정여부 차이가 있다. Numpy Array는 2차원 이상의 Matrix, pandas Dataframe은 Table을 표현하기 위해 만들어졌다. 컬럼이 존재하기 때문에 계산 효율성은 Numpy보다 떨어지지만 컬럼명을 사용할 수 있어 많은 분석 및 시각화 라이브러리가 Dataframe 형식을 지원한다. 


## 1. Load Dataset
### 1.1 Create a dataframe
```python
df = pd.DataFrame({
    'col1': [1, 2], 
    'col2': [3, 4]
    })                  # create from dict

df['col3'] = [5, 6]     # add column

#    col1  col2  col3
# 0     1     3     5
# 1     2     4     6
```
`pd.DataFrame()`을 사용하면 빈 데이터프레임을 만들 수 있다. 딕셔너리, 리스트, Numpy Array 등을 사용해서도 빈 데이터프레임을 만들 수 있다. 만들어진 데이터프레임에 `df['col3']`처럼 컬럼을 추가하는 것도 가능하다.

### 1.2 Load data from file
```python
import pandas as pd

# Read data from file
df1 = pd.read_csv('FILEPATH.csv', header=None)  # csv
df2 = pd.read_csv('FILEPATH.tsv', sep='\t')     # tsv, sep an alias for delimiter
df3 = pd.read_excel('FILEPATH.xlsx')

# Read data from url
df4 = pd.read_csv(URLPATH)

# read data from string
from io import StringIO

df5 = pd.DataFrame(StringIO())                     # string
```
`pd.read_csv()` 함수를 사용하면 로컬 파일에서 데이터를 불러올 수 있다. `sep` 파라미터로 구분자를 지정해주면 tsv(tab-seperated values)나 txt파일도 읽어올 수 있다. 

`pd.read_csv()`는 기본적으로 데이터 첫 줄을 헤더로 인식한다. `header=None`을 사용해야 첫 줄부터 데이터로 인식한다. `pd.read_excel()` 함수로 엑셀 파일도 비슷한 방식으로 읽어올 수 있다.

외부 링크에서 파일을 직접 불러오는 것도 `pd.read_csv()`로 가능하다. 로컬 파일 경로 대신 외부 URL 주소를 입력하면 된다. 물론 해당 주소와 파일 형식이 올바른 것이어야 한다. 

### 1.3 Check data property
```python
df.shape      # check number of rows and columns of dataframe
df.head(n=5)  # check first 5 rows of dataframe
df.tail(n=5)  # check last 5 rows of dataframe

df.index      # check index (rownums)
df.columns    # check columns
df.dtypes     # check datatype
```

데이터를 불러오면 먼저 크기 확인을 하자. 너무 큰 데이터셋을 한 번에 조회하면 시스템 부하가 커진다.  

`data.shape`는 전체 데이터의 행과 열 개수를 튜플로 반환한다. `df.head()`, `df.tail()`은 각각 전체 데이터의 앞뒤 일부 데이터만을 보여준다. 패러미터를 사용해 보여줄 행의 수를 조절할 수 있다.

`df.index`, `df.columns`는 각각 행과 열 이름을 알려준다. 특히 열 이름은 변수명인 경우가 많아 자주 확인하게 된다. `df.dtype`으로 데이터프레임 각 열의 자료형을 확인할 수 있다.

### 1.4 More on datatype
```python
# check datatype
df.dtypes     

# changing datatype
df.column1.astype('int')    # to integer

# pre-defined datatype
df_dtypes = {
    'column1' : 'str',
    'column2' : 'int'
}
df = pd.read_csv('FILEPATH.csv', dtype=df_dtypes)
```

데이터 타입을 좀 더 자세히 살펴보자. pandas 데이터 분석에서 문제가 발생하는 경우 대부분은 데이터 타입 문제다. 

`df.dtypes`를 사용하면 현재 데이터프레임의 데이터 타입을 확인할 수 있다. 자주 사용하는 데이터 타입은 아래와 같다. 더 많은 데이터 타입이 존재하며 직접 데이터 타입을 만들 수도 있다. 보다 자세한 내용은 [공식 홈페이지](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)를 참고하자. 

- `'datetime64'`    : 날짜
- `'int'`           : 정수
- `'str'`           : 문자열
- `'float'`         : 부동소수점
- `'boolean'`       : 불(부울)
- `'category'`      : 카테고리

`df.astype`을 사용하면 특정 자료형으로 변경할 수 있다. 날짜 데이터가 문자열 자료형으로 되어있을 경우, 적절히 데이터 타입을 변경해주지 않으면 분석에 오류가 생길 수 있다.

`read_csv()`의 `dtype` 파라미터를 사용하면 데이터를 불러오는 단계에서부터 적절한 자료형을 지정해줄 수 있다. 일반적인 자료형 파라미터를 넣을 수도 있고, 컬럼별로 자료형을 지정한 딕셔너리를 넣을 수도 있다.  

### 1.5 Save data to file
```python 
df.to_csv('FILEPATH.csv',           # save as csv file
          header=None,              # don't use header (column name) 
          index=False,              # don't use index (row number)
          encoding='utf-8-sig')     # for korean encoding
df.to_excel('FILEPATH.xlsx')        # also can save as excel file
```
처리가 끝난 데이터프레임은 `to_csv`, `to_excel`을 사용해 파일 형태로 저장할 수 있다. `pd.read_csv()`와 같이 `header=True`이면 첫번째 행을 열이름으로 사용한다는 뜻이며 `None`으로 할 경우 열이름 없이 첫번째 행부터 데이터가 된다. `index=True`일 경우 첫 열에 행번호가 삽입되며, `None`으로 할 경우 기존 데이터의 첫 열을 그대로 사용한다.

데이터 인코딩 방식은 `utf-8`, `euc-kr`, `cp949` 등을 주로 사용한다. `utf-8` 형식으로 저장한 데이터가 깨져서 나올 경우 대신 `encoding='utf-8-sig'`옵션을 설정해준다. 'sig'는 'signiture'의 약자로 해당 옵션을 사용하면 BOM(Byte order mark) 형식으로 파일을 저장한다.


## 2. Sort
### 2.1 Sort numerical values
```python
df.sort_values(by=['컬럼명1', '컬럼명2', ...], ascending=True, inplace=True)
```
데이터프레임의 특정 열을 기준으로 데이터 값을 정렬하고 싶을 때 `df.sort_values()`를 사용할 수 있다. `inplace=True`를 사용하면 원본 데이터프레임을 정렬하고 `inplace=False`면 정렬된 데이터프레임을 반환한다. `ascending=True`일 경우 오름차순(작은 수가 먼저), `False`일 경우 내림차순(큰 수가 먼저) 정렬한다. 동률일 경우 `by` 파라미터에 지정한 열순으로 정렬한다. 

### 2.2 Sort ordinal values
```python
dayname = ['월','화','수','목','금','토','일']
```
범주형 데이터*Categorical Data*는 순서가 존재하지 않는 명목형 데이터*Norminal Data*와 순서가 존재하는 순서형 데이터*Ordinal Data*가 있다. 분석 시 범주형 데이터의 순서를 지정해야 하는 경우가 종종 있다. 대표적으로 요일 데이터가 그렇다. 

※ 엄밀히 말하면 요일의 순서는 정보성이 없기 때문에 순서형 데이터라고 부를 수 없다. 그러나 실제 분석에서는 시각화 등의 이유로 적절한 순서를 주기 때문에 편의상 순서형 데이터라고 하겠다. 

- 범주형 데이터 *Categorical Data*
    * 명목형 데이터 *Norminal Data* : 순서 존재 X
    * 순서형 데이터 *Ordinal Data*  : 순서 존재 O
- 수치형 데이터 *Numeric Data*
    * 이산형 데이터 *Discrete Data*
    * 연속형 데이터 *Continuous Data*

```python
# method 1: pd.Categorical()
df['요일_순서2'] = pd.Categorical(df['요일'], categories=dayname)

# method 2: pd.CategoricalDtype()
dtype_dayname = pd.CategoricalDtype(dayname, ordered=True)  # ordered=True for ordinal data
df['요일_순서1'] = df['요일'].astype(dtype_dayname)          # df.astype('category')
```

첫번째 방법으로 `pd.Categorical()`를 사용하면 범주형 데이터에 순서를 줘서 순서형 데이터로 바꿀 수 있다. `categories` 파라미터에 사전에 순서대로 정렬한 리스트를 넣어주면 된다.

두번째 방법으로 `pd.CategoricalDtype(orderd=True)`를 사용해서 아예 새로운 자료형을 만들 수도 있다. 일단 새로운 자료형을 만들면 `df.astype()`이나 `pd.read_csv()` 함수에서 사용할 수 있다. 두번째 방법은 자료형 자체를 생성하기 때문에 데이터를 불러오는 단계에서부터 사용할 수 있다는 것이 장점이다. 

둘 중 하나의 방법으로 순서를 부여한 뒤에는 위의 정렬 함수를 사용해서 정렬하면 된다. 


## 3. Indexing and Slicing
### 3.1 Indexing
```python
df.iloc[[1,3,5], [3,4]]
```
인덱싱은 데이터프레임에서 특정 열 혹은 행을 선택하는 기법이다. `df.iloc`를 쓰면 데이터프레임의 특정 부분을 선택할 수 있다. `df.iloc`를 사용하면 정해진 행, 열의 위치를 입력해서 원하는 데이터를 추출할 수 있으며 복수의 인덱스를 입력하는 것도 가능하다.

### 3.2 Slicing
```python
df.iloc[:,start:end]    # Column Slicing
df.iloc[start:end,:]    # Row Slicing

df.iloc[:,:]            # Total Data
df.iloc[:,0]            # Data from First column
df.iloc[3:5,:]          # 3rd and 4th Data
```

슬라이싱은 데이터프레임에서 범위를 지정하여 여러 행이나 열의 데이터를 선택하는 기법이다. 인덱싱과는 구분되어 있지만 실무에서는 거의 구분없이 사용한다. 슬라이싱 코드에서 `:`는 전체 범위를 의미한다. 

`df.iloc[:,0]`은 첫번째 열의 데이터를 선택하는데 이러한 방식을 열 슬라이싱*Column Slicing*이라고 한다. 반면 행 슬라이싱*Row Slicing* 특정 범위의 행을 선택한다. 예를 들어 `df.iloc[0,:]`은 첫번째 행을 선택한다.

※ `df.loc`를 사용하면 라벨 기반 인덱싱 및 슬라이싱이 가능하다. 

### 3.3 Boolean Indexing
```python
df_filtered = df[df['column_name'] > 50] # 'column_name'값이 50보다 큰 데이터 선택

```
불리언 인덱싱*Boolean Indexing*을 사용하면 조건에 따라 데이터를 선택할 수 있다. 특정 열에서 50보다 큰 값을 가진 행만 선택하려면 위와 같이 사용할 수 있다.

### 3.4 Index Method
```python
df['column'].isin(target_vals)
df['column'].between(min_val, max_val)
```
`df.isin()`, `df.between()` 등의 메서드를 사용하면 인덱싱을 더 편리하게 할 수 있다. `df.isin()`는 원하는 값이 존재하는 데이터만 걸러낼 때 사용하며, 특히 **비교 연산을 사용할 수 없는 범주형 데이터 처리**에 유용하다. `df.between()`는 두 값 사이에 있는 데이터만을 반환한다. **2표준편차 범위 밖 이상치 제거** 시 사용할 수 있다.

### 3.5 Replacing Values 
```python
# 값 대체 예제
df.replace({'old_value': 'new_value'})
```
`df.replace`를 쓰면 데이터프레임에서 특정 값을 다른 값으로 바꿀 수 있다. `old_value`를 `new_value`로 바꾸려면 위와 같이 사용한다. 예를 들어 데이터의 성별값이 `0`,`1`로 코딩되어 있다면 `df.replace`로 `여성`, `남성`으로 바꿀 수 있다.

### 3.6 Column renaming
```python
# Method 1. 
df = df.rename(columns={prev:new})

# Method 2.
df.columns = ['new_name1', 'new_name2', 'new_name3']
```
데이터프레임의 컬럼명을 바꾸려면 `df.rename()` 사용한다. 파라미터로 딕셔너리를 사용하여 기존의 열 이름을 키로, 바꿀 열 이름을 값으로 넣어주면 된다. `df.columns`를 변경하여 전체 컬럼명을 변경할 수도 있다.


## 4. Nullity Handling
### 4.1 NaN check
```python
df.isna()
df.isna().sum()
```
`df.isna()` 메서드를 사용하면 `NaN`값이 있는 위치만 `True`인 데이터프레임을 반환한다. `sum()` 함수와 같이 사용하면 전체 결측값 개수도 알 수 있다. 이 결측값을 어떻게 처리하는가? 크게 두 가지 선택이 있는데 첫째는 아예 해당 데이터를 제거하는 것이고, 둘째는 결측값을 다른 값으로 대체하는 것이다. 

### 4.2 Drop NaN data
```python
df.dropna(
    axis='rows',            # 옵션: 'rows', 'columns'
    how='any'               # 옵션: 'any', 'all'
    subset=['COLUMN_NAME'], # 특정 컬럼의 NaN 데이터만 확인
    thresh=10,              # NaN이 아닌 데이터가 최소 10건 이상인 컬럼만
    inplace=True
)
```
`df.dropna()` 함수를 사용하면 결측값이 있는 시행을 제거할 수 있다. 다른 pandas 함수와 유사하게 `inplace=True`를 사용하면 원본 데이터프레임에서 결측값이 삭제되고 `inplace=False`면 결측값이 삭제된 데이터프레임을 반환한다.

`axis`는 결측이 있는 행을 지울지, 열을 지울지 선택한다. 기본값은 `rows`다. 파라미터 값에 따라 결측값이 존재하는 행(또는 열) 데이터를 지운다.

`how='any'`는 결측값이 하나라도 존재할 경우 해당 행(또는 열)을 제거하도록 하는 파라미터다. `how='all'`로 설정했다면 해당 행(또는 열)이 모두 결측값이어야 제외된다. 

`thresh`는 결측값이 없는 데이터가 최소 N개 이상이어야 한다는 조건을 적용한다. 따라서 `how` 패러미터와는 동시에 사용할 수 없다. `subset`은 일부 컬럼에만 결측값 조건을 적용한다.

### 4.3 Fill NaN data
```python
df.fillna(0, inplace=True)  # 0으로 결측값을 대체한다.
df.fillna(df.mean())        # 각 컬럼의 평균값으로 결측값을 대체한다.
```
`df.fillna()` 함수는 결측값를 전부 특정값으로 바꿔준다. 일반적으로 결측값을 대체할 경우 평균, 중앙값, 최빈값, 0 등으로 대체한다. 

특정값 대신 주위의 값으로 바꿔주는 함수도 존재한다. `df.ffill`, `df.bfill` 등인데 자세한 내용은 [공식 홈페이지](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html#pandas.DataFrame.ffill)를 참고하자.


## 5. Unique and Duplicated Values
### 5-1. Unique Values
```python
# Get unique values of a column
df['col1'].unique()

# Number of unique values
df.nunique()
```
`df['col'].unique()`는 특정 컬럼(Pandas Series)에서 중복을 제외한 값을 보여준다. 특정 변수의 유일한 값을 알고 싶을 때 사용한다. `.unique()`는 데이터프레임에는 사용할 수 없다.

`df.nunique()`를 사용하면 각 컬럼별 (중복을 제외한) 데이터의 크기를 확인할 수 있다.

### 5-2. Duplicated Values
```python
# Get duplicated values of a dataframe
df.duplicated(subset=None, keep='first')

# Drop duplicated values
df.drop_duplicates(subset=None, keep='last', inplace=True)
```
`df.duplicated()`를 사용하면 데이터프레임의 중복을 알 수 있다. `subset`은 중복을 확인할 컬럼을 지칭하며 기본값 `None`을 사용하면 전체 컬럼에 대해 중복을 확인한다. `keep='first'`로 설정하면 중복값 중 첫번째 값을 남긴다.

중복값을 제거한 데이터를 얻기 위해 `df.drop_duplicates()`를 사용한다. `subset`, `keep`의 사용방법은 `df.duplicated()`와 동일하며 `inplace` 패러미터도 자주 사용한다.

## References
* [pandas.read_csv — pandas 2.1.4 documentation - PyData](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)
* [pandas.CategoricalDtype — pandas 2.1.4 documentation](https://pandas.pydata.org/docs/reference/api/pandas.CategoricalDtype.html)
* [Essential basic functionality — pandas 2.1.4 documentation](https://pandas.pydata.org/docs/user_guide/basics.html#dtypes)
* [pandas.Index.isin — pandas 2.1.4 documentation - PyData |](https://pandas.pydata.org/docs/reference/api/pandas.Index.isin.html)
* [Pandas - read_csv 컬럼 타입 지정 - Passwd - 티스토리](https://passwd.tistory.com/entry/Python-Pandas-readcsv-%EC%BB%AC%EB%9F%BC-%ED%83%80%EC%9E%85-%EC%A7%80%EC%A0%95)
